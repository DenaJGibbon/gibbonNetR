[{"path":"https://denajgibbon.github.io/gibbonNetR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 gibbonNetR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"first-load-the-package","dir":"Articles","previous_headings":"Data Preparation","what":"First load the package","title":"1. Multiclass models","text":"","code":"library(gibbonNetR)"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"we-create-spectrogram-images-of-the-sound-files-","dir":"Articles","previous_headings":"Data Preparation","what":"We create spectrogram images of the sound files.","title":"1. Multiclass models","text":"follow best practices want use training test data different passive acoustic monitoring arrays clips Danum Valley Conservation Area, Sabah, Malaysia, taken two different arrays. “spectrogram_images” function takes folders organized labeled signal type, creates training, validation, test folders using “splits” specified function call. example 70% data used training 30% validation. “Representative spectrogram images”","code":"# Link to training clips on Zenodo ZenodoLink <- 'https://zenodo.org/records/14212086/files/trainingclips.zip?download=1'  # Download into specified zip file location download.file(url = ZenodoLink, destfile = 'data/trainingclips.zip',method='curl')  # Unzip folder exdir <- 'data/' utils::unzip(zipfile = 'data/trainingclips.zip', exdir = exdir )  # Check folder composition TrainingDatapath <- paste(exdir,\"trainingclips\",sep='')  # Check folder names list.files(TrainingDatapath)  # Create spectrogram images spectrogram_images(    trainingBasePath = TrainingDatapath,    outputBasePath = 'data/trainingimages/',    minfreq.khz = 0.4,    maxfreq.khz = 1.6,    random=FALSE,    splits = c(0.7, 0.3, 0), # Assign proportion to training, validation, or test folders    new.sampleratehz = 'NA'  )"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"download-example-test-files-on-zenodo-and-convert-to-spectrogram-images","dir":"Articles","previous_headings":"Data Preparation","what":"Download example test files on Zenodo and convert to spectrogram images","title":"1. Multiclass models","text":"“spectrogram_images” function puts 100% test images test folder.","code":"library(gibbonNetR)  # Link to training clips on Zenodo ZenodoLink <- 'https://zenodo.org/records/14212086/files/testclips.zip?download=1'  # Download into specified zip file location download.file(url = ZenodoLink, destfile = 'data/testclips.zip',method='curl')  # Unzip folder exdir <- 'data/' utils::unzip(zipfile = 'data/testclips.zip', exdir = exdir )  # Check folder composition TestDatapath <- paste(exdir,\"testclips\",sep='')  # Check folder names list.files(TestDatapath)  # Create spectorgram images spectrogram_images(    trainingBasePath = TestDatapath,    outputBasePath = 'data/testimages/',    minfreq.khz = 0.4,    maxfreq.khz = 1.6,    splits = c(0, 0, 1), # Assign proportion to training, validation, or test folders    new.sampleratehz = 'NA'  )"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"model-training","dir":"Articles","previous_headings":"","what":"Model training","title":"1. Multiclass models","text":"start multi-class model. use spectrogram images training, test validation created . Note “input.data.path” train valid folders need . test data, path must contain ‘test’ folder. can specify multiple model architectures number epochs training.","code":"# Location of spectrogram images for training input.data.path <-  'data/trainingimages/'  # Location of spectrogram images for testing test.data.path <- 'data/testimages/test/'  # User specified training data label for metadata trainingfolder.short <- 'danummulticlassexample'  # Specify the architecture type architecture <- c('alexnet','resnet50') # Choose 'alexnet', 'vgg16', 'vgg19', 'resnet18', 'resnet50', or 'resnet152'  # We can specify the number of epochs to train here epoch.iterations <- c(1)  # Function to train a multi-class CNN gibbonNetR::train_CNN_multi(input.data.path=input.data.path,                             architecture =architecture,                             learning_rate = 0.001,                             class_weights = c(0.3, 0.3, 0.2, 0.2, 0),                             test.data=test.data.path,                             unfreeze.param = TRUE,                             epoch.iterations=epoch.iterations,                             save.model= TRUE,                             early.stop = \"yes\",                             output.base.path = \"data/model_output/\",                             trainingfolder=trainingfolder.short,                             noise.category = \"noise\")"},{"path":[]},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"specify-for-the-female-gibbon-class","dir":"Articles","previous_headings":"Model evaluation","what":"Specify for the ‘female.gibbon’ class","title":"1. Multiclass models","text":"","code":"# Evaluate model performance performancetables.dir <- \"data/model_output/_danummulticlassexample_multi_unfrozen_TRUE_/performance_tables_multi\"  PerformanceOutput <- gibbonNetR::get_best_performance(performancetables.dir=performancetables.dir,                                                       class='female.gibbon',                                                       model.type = \"multi\",Thresh.val=0) # Evaluate model performance performancetables.dir <- \"/Users/denaclink/Desktop/RStudioProjects/gibbonNetR/data/model_output/_danummulticlassexample_multi_unfrozen_TRUE_/performance_tables_multi\"  PerformanceOutput <- gibbonNetR::get_best_performance(performancetables.dir=performancetables.dir,                                                       class='female.gibbon',                                                       model.type = \"multi\",Thresh.val=0)"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"examine-the-results","dir":"Articles","previous_headings":"Model evaluation","what":"Examine the results","title":"1. Multiclass models","text":"Note expect great performance since trained one epoch. “Output ‘get_best_performance’ fuction”","code":"PerformanceOutput$f1_plot  PerformanceOutput$best_f1$F1 [1] 0.4862252  PerformanceOutput$best_auc$AUC [1] 0.2858019  PerformanceOutput$best_precision$Precision [1] 0.321817  PerformanceOutput$best_recall$Recall [1] 1"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/Training multiclass models.html","id":"trained-model-evaluation","dir":"Articles","previous_headings":"","what":"Trained model evaluation","title":"1. Multiclass models","text":"can deploy trained model another test dataset see well performs. case, test data organized folders corresponding labels match training data. want create spectrogram images new test dataset. sample rate original files higher (48 kHz) use downsample call function make sure spectrogram images resolution. ‘evaluate_trainedmodel_performance_multi’ function compare model performance pretrained models another test dataset. Now can use function ‘get_best_performance’ investigate model performance. see high F1 score across thresholds ‘female.gibbon’ class “Output ‘get_best_performance’ fuction”","code":"Modify the script above to download the apppropriate test files ZenodoLink <- 'https://zenodo.org/records/14212086/files/testclipsmaliau.zip?download=1' TestDatapath <- 'data/testclipsmaliau'  # Create spectorgram images spectrogram_images(    trainingBasePath = TestDatapath,    outputBasePath = 'data/testimagesmaliau/',    minfreq.khz = 0.4,    maxfreq.khz = 1.6,    splits = c(0, 0, 1), # Assign proportion to training, validation, or test folders    new.sampleratehz = 16000  ) trained_models_dir <- '/Users/denaclink/Desktop/RStudioProjects/gibbonNetR/data/model_output/_danummulticlassexample_multi_unfrozen_TRUE_/'  class_names <- dput(list.files('/Users/denaclink/Desktop/RStudioProjects/gibbonNetR/data/trainingimages/train/'))  image_data_dir <- 'data/testimagesmaliau/test/'  dir.create('/data/model_output_test/',recursive = T)  evaluate_trainedmodel_performance_multi(trained_models_dir=trained_models_dir,                                           class_names=class_names,                                           image_data_dir=image_data_dir,                                            output_dir= 'data/model_output_test/',                                            noise.category = \"noise\") # Evaluate model performance performancetables.dir <- \"data/model_output_test/performance_tables_multi_trained/\"  PerformanceOutput <- gibbonNetR::get_best_performance(performancetables.dir=performancetables.dir,                                                       class='female.gibbon',                                                       model.type = \"multi\",Thresh.val=0)"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/UnsupervisedClustering.html","id":"extract-embeddings","dir":"Articles","previous_headings":"","what":"Extract embeddings","title":"4. Unsupervised clustering","text":"Use pre-trained model extract embeddings use unsupervised clustering identify signals","code":"ModelPath <- \"model_output/_danummulticlassexample_multi_unfrozen_TRUE_/_danummulticlassexample_20_resnet50_model.pt\" result <- extract_embeddings(test_input=\"data/examples/test/\",                                       model_path=ModelPath,                                      target_class = \"female.gibbon\")"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/UnsupervisedClustering.html","id":"we-can-plot-the-unsupervised-clustering-results","dir":"Articles","previous_headings":"Extract embeddings","what":"We can plot the unsupervised clustering results","title":"4. Unsupervised clustering","text":"","code":"result$EmbeddingsCombined"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/UnsupervisedClustering.html","id":"we-can-explore-the-unsupervised-clustering-results","dir":"Articles","previous_headings":"Extract embeddings > We can plot the unsupervised clustering results","what":"We can explore the unsupervised clustering results","title":"4. Unsupervised clustering","text":"can see Normalize Mutual Information score confusion matrix results use ‘hdbscan’ match target class cluster largest number observations","code":"result$NMI result$ConfusionMatrix"},{"path":"https://denajgibbon.github.io/gibbonNetR/articles/UnsupervisedClustering.html","id":"we-can-then-deploy-the-model-over-longer-sound-files-","dir":"Articles","previous_headings":"Extract embeddings","what":"We can then deploy the model over longer sound files.","title":"4. Unsupervised clustering","text":"","code":"library(gibbonNetR)         # Load data    data(\"TempBinWav\")     # Save in temp directory    dir.create(paste(tempdir(),'/MultiDir/Wav/',sep=''),recursive = T, showWarnings = FALSE)     # Write to temp directory    writeWave(TempBinWav,filename = paste(tempdir(),'/MultiDir/Wav/','TempBinWav.wav',sep=''))     # Find model path    # Set model directory    trained_models_dir <- system.file(\"extdata\", \"trainedresnetmulti/\", package = \"gibbonNetR\")     # Specify model path    ModelPath <- list.files(trained_models_dir,full.names = T)     # Deploy trained model over sound files    deploy_CNN_multi(      clip_duration = 12,      architecture='resnet18',      output_folder = paste(tempdir(),'/MultiDir/Results/Images/',sep=''),      output_folder_selections = paste(tempdir(),'/MultiDir/Results/Selections/',sep=''),      output_folder_wav = paste(tempdir(),'/MultiDir/Results/Wavs/',sep=''),      detect_pattern=NA,      top_model_path = ModelPath,      path_to_files = paste(tempdir(),'/MultiDir/Wav/',sep=''),      downsample_rate = 'NA',      save_wav = F,      class_names = c('female.gibbon','hornbill.helmeted','hornbill.rhino','long.argus','noise'),      noise_category = 'noise',      single_class = FALSE,      single_class_category = 'female.gibbon',      threshold = .25,      max_freq_khz = 2    )"},{"path":"https://denajgibbon.github.io/gibbonNetR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dena J. Clink. Author, maintainer.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clink DJ, Ahmad AH (2023). gibbonNetR: R Package Use CNNs Transfer Learning Acoustic Data. https://github.com/DenaJGibbon/gibbonNetR.","code":"@Manual{,   title = {gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data},   year = {2023},   author = {Dena J. Clink and Abdul Hamid Ahmad},   journal = {GitHub},   url = {https://github.com/DenaJGibbon/gibbonNetR}, }"},{"path":"https://denajgibbon.github.io/gibbonNetR/index.html","id":"overview","dir":"","previous_headings":"","what":"gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data","title":"gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data","text":"README provides code training testing performance different convolutional neural network model architectures spectrogram images.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data","text":"detailed usage guide can found : denajgibbon.github.io/gibbonNetR/","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data","text":"can install gibbonNetR package repository using devtools:","code":"# If you don't have devtools installed install.packages(\"devtools\")  # Install gibbonNetR devtools::install_github(\"https://github.com/DenaJGibbon/gibbonNetR\")  # The first time you use the package 'torch' will need to install additional packages. You can start the process using the following: library(torch)"},{"path":"https://denajgibbon.github.io/gibbonNetR/index.html","id":"quickstart-guide","dir":"","previous_headings":"","what":"Quickstart guide","title":"gibbonNetR: R Package for the Use of CNNs and Transfer Learning on Acoustic Data","text":"","code":"library(gibbonNetR)    # Set file path to spectorgram images     filepath <- system.file(\"extdata\", \"multiclass/\", package = \"gibbonNetR\")    # Train simple CNN model   train_CNN_multi(     input.data.path = filepath,     test.data = paste(filepath,'/test/',sep=''),     architecture = \"alexnet\",  # Choose 'alexnet', 'vgg16', 'vgg19', 'resnet18', 'resnet50', or 'resnet152'     unfreeze.param = TRUE,     batch_size = 6,     class_weights = rep( (1/5), 5),     learning_rate = 0.001,     epoch.iterations = 1,  # Or any other list of integer epochs     early.stop = \"yes\",     save.model= FALSE,     output.base.path = paste(tempdir(),'/MultiDir/',sep=''),     trainingfolder = \"test_multi\",     noise.category = 'noise'   )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/TempBinWav.html","id":null,"dir":"Reference","previous_headings":"","what":"A short .wav file for automated detection tests. — TempBinWav","title":"A short .wav file for automated detection tests. — TempBinWav","text":"short .wav file automated detection tests.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/TempBinWav.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A short .wav file for automated detection tests. — TempBinWav","text":"","code":"TempBinWav"},{"path":[]},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/TempBinWav.html","id":"tempbinwav","dir":"Reference","previous_headings":"","what":"TempBinWav","title":"A short .wav file for automated detection tests. — TempBinWav","text":"data frame 7,240 rows 60 columns: country Malaysia year 2024","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/TempBinWav.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"A short .wav file for automated detection tests. — TempBinWav","text":"https://doi.org/10.5281/zenodo.10927637","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Transfer Learning from Sound Directories — deploy_CNN_binary","title":"Transfer Learning from Sound Directories — deploy_CNN_binary","text":"function processes sound data specified directory, performs transfer learning using pre-trained deep learning model, saves results.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transfer Learning from Sound Directories — deploy_CNN_binary","text":"","code":"deploy_CNN_binary(   output_folder,   output_folder_selections,   output_folder_wav,   top_model_path,   path_to_files,   detect_pattern = NA,   architecture,   clip_duration = 12,   hop_size = 6,   downsample_rate = 16000,   threshold = 0.5,   save_wav = TRUE,   positive.class = \"Gibbons\",   negative.class = \"Noise\",   max_freq_khz = 2 )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transfer Learning from Sound Directories — deploy_CNN_binary","text":"output_folder character string specifying path output folder results saved. output_folder_selections character string specifying path folder selection tables saved. output_folder_wav character string specifying path folder extracted WAV files saved. top_model_path character string specifying path pre-trained top model classification. path_to_files character string specifying path directory containing sound files process. detect_pattern (optional) character string specifying pattern detect file names. Default NA. architecture character string specifying architecture pre-trained model. clip_duration duration sound clip seconds. hop_size hop size splitting sound clips. downsample_rate downsample rate audio Hz. Set 'NA' downsampling required. threshold threshold audio detection. save_wav logical value indicating whether save extracted sound clips WAV files. Default TRUE. positive.class character string specifying positive class label. Default 'Gibbons'. negative.class character string specifying negative class label. Default 'Noise'. max_freq_khz maximum frequency kHz spectrogram visualization. Default 2.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_binary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transfer Learning from Sound Directories — deploy_CNN_binary","text":"function processes sound data directory, extracts sound clips, converts images, performs image classification using pre-trained deep learning model, saves results including selection tables image audio files.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transfer Learning from Sound Directories — deploy_CNN_binary","text":"","code":"{ if (.Platform$OS.type == \"windows\") {    #' Load data   data(\"TempBinWav\")    dir.create(paste(tempdir(),'\\\\BinaryDir\\\\Wav\\\\',sep=''),recursive = TRUE, showWarnings = T)    #' Write to temp directory   writeWave(TempBinWav,filename = paste(tempdir(),'\\\\BinaryDir\\\\Wav\\\\','TempBinWav.wav',sep=''))    #' Set model directory   trained_models_dir <- system.file(\"extdata\", \"trainedresnetbinary\\\\\", package = \"gibbonNetR\")    #' Specify model path   ModelPath <- list.files(trained_models_dir,full.names =TRUE)     deploy_CNN_binary (     clip_duration = 12,     architecture='alexnet',     output_folder = paste(tempdir(),'\\\\BinaryDir\\\\Results\\\\Images\\\\',sep=''),     output_folder_selections = paste(tempdir(),'\\\\BinaryDir\\\\Results\\\\Selections\\\\',sep=''),     output_folder_wav = paste(tempdir(),'\\\\BinaryDir\\\\Results\\\\Wavs\\\\',sep=''),     detect_pattern=NA,     top_model_path = ModelPath,     path_to_files = paste(tempdir(),'\\\\BinaryDir\\\\Wav\\\\',sep=''),     downsample_rate = 'NA',     threshold = 0.5,     save_wav = F,     positive.class = 'Gibbons',     negative.class = 'Noise',     max_freq_khz = 2   )   } else  {   #' Load data   data(\"TempBinWav\")    dir.create(paste(tempdir(),'/BinaryDir/Wav/',sep=''),recursive = TRUE, showWarnings = FALSE)    #' Write to temp directory   writeWave(TempBinWav,filename = paste(tempdir(),'/BinaryDir/Wav/','TempBinWav.wav',sep=''))    #' Set model directory   trained_models_dir <- system.file(\"extdata\", \"trainedresnetbinary/\", package = \"gibbonNetR\")    #' Specify model path   ModelPath <- list.files(trained_models_dir,full.names =TRUE)     deploy_CNN_binary (     clip_duration = 12,     architecture='alexnet',     output_folder = paste(tempdir(),'/BinaryDir/Results/Images/',sep=''),     output_folder_selections = paste(tempdir(),'/BinaryDir/Results/Selections/',sep=''),     output_folder_wav = paste(tempdir(),'/BinaryDir/Results/Wavs/',sep=''),     detect_pattern=NA,     top_model_path = ModelPath,     path_to_files = paste(tempdir(),'/BinaryDir/Wav/',sep=''),     downsample_rate = 'NA',     threshold = 0.5,     save_wav = F,     positive.class = 'Gibbons',     negative.class = 'Noise',     max_freq_khz = 2   ) } } #> Error in cpp_tensor_load(obj$values, device, base64): Lantern is not loaded. Please use `install_torch()` to install additional dependencies."},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Transfer Learning from Sound Directories — deploy_CNN_multi","title":"Transfer Learning from Sound Directories — deploy_CNN_multi","text":"function processes sound data specified directory, performs transfer learning using pre-trained deep learning model, saves results.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transfer Learning from Sound Directories — deploy_CNN_multi","text":"","code":"deploy_CNN_multi(   output_folder,   output_folder_selections,   output_folder_wav,   top_model_path,   path_to_files,   detect_pattern = NA,   architecture,   clip_duration = 12,   hop_size = 6,   downsample_rate = 16000,   threshold = 0.1,   save_wav = TRUE,   class_names = c(\"female.gibbon\", \"hornbill.helmeted\", \"hornbill.rhino\", \"long.argus\",     \"noise\"),   noise_category = \"noise\",   max_freq_khz = 2,   single_class = TRUE,   single_class_category = \"female.gibbon\",   for_prrec = TRUE )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transfer Learning from Sound Directories — deploy_CNN_multi","text":"output_folder character string specifying path output folder results saved. output_folder_selections character string specifying path folder selection tables saved. output_folder_wav character string specifying path folder extracted WAV files saved. top_model_path character string specifying path pre-trained top model classification. path_to_files character string specifying path directory list containing sound files process. detect_pattern Pattern sound file detect subset. architecture User specified: 'alexnet', 'vgg16', 'vgg19', 'resnet18', 'resnet50', 'resnet152' clip_duration duration sound clip seconds. hop_size hop size splitting sound clips. downsample_rate downsample rate audio Hz, set 'NA' downsampling required. threshold threshold audio detection. save_wav logical value indicating whether save extracted sound clips WAV files. class_names character vector containing unique classes training model. noise_category character string specifying noise category exclusion. max_freq_khz maximum frequency kHz spectrogram visualization. single_class logical value indicating whether process single class. now 'TRUE' option. single_class_category character string specifying single class category 'single_class' set TRUE. for_prrec Whether output detections create PR curve.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transfer Learning from Sound Directories — deploy_CNN_multi","text":"function processes sound data directory, extracts sound clips, converts images, performs image classification using pre-trained deep learning model, saves results including selection tables image audio files.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/deploy_CNN_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transfer Learning from Sound Directories — deploy_CNN_multi","text":"","code":"{ if (.Platform$OS.type == \"windows\") {    # Load data   data(\"TempBinWav\")    dir.create(paste(tempdir(),'\\\\MultiDir\\\\Wav\\\\',sep=''),recursive = TRUE, showWarnings = FALSE)    # Write to temp directory   writeWave(TempBinWav,filename = paste(tempdir(),'\\\\MultiDir\\\\Wav\\\\','TempBinWav.wav',sep=''))    #' Set model directory   trained_models_dir <- system.file(\"extdata\", \"trainedresnetmulti\\\\\", package = \"gibbonNetR\")    #' Specify model path   ModelPath <- list.files(trained_models_dir,full.names = TRUE)    #' Deploy trained model over sound files   deploy_CNN_multi(     clip_duration = 12,     architecture='resnet18',     output_folder = paste(tempdir(),'\\\\MultiDir\\\\Results\\\\Images\\\\',sep=''),     output_folder_selections = paste(tempdir(),'\\\\MultiDir\\\\Results\\\\Selections\\\\',sep=''),     output_folder_wav = paste(tempdir(),'\\\\MultiDir\\\\Results\\\\Wavs\\\\',sep=''),     detect_pattern=NA,     top_model_path = ModelPath,     path_to_files = paste(tempdir(),'\\\\MultiDir\\\\Wav\\\\',sep=''),     downsample_rate = 'NA',     save_wav = F,     class_names = c('female.gibbon','hornbill.helmeted','hornbill.rhino','long.argus','noise'),     noise_category = 'noise',     single_class = FALSE,     threshold = .25,     max_freq_khz = 2   ) } else  {    # Load data   data(\"TempBinWav\")    dir.create(paste(tempdir(),'/MultiDir/Wav/',sep=''),recursive = TRUE, showWarnings = FALSE)    # Write to temp directory   writeWave(TempBinWav,filename = paste(tempdir(),'/MultiDir/Wav/','TempBinWav.wav',sep=''))    #' Set model directory   trained_models_dir <- system.file(\"extdata\", \"trainedresnetmulti/\", package = \"gibbonNetR\")    #' Specify model path   ModelPath <- list.files(trained_models_dir,full.names = TRUE)    #' Deploy trained model over sound files   deploy_CNN_multi(     clip_duration = 12,     architecture='resnet18',     output_folder = paste(tempdir(),'/MultiDir/Results/Images/',sep=''),     output_folder_selections = paste(tempdir(),'/MultiDir/Results/Selections/',sep=''),     output_folder_wav = paste(tempdir(),'/MultiDir/Results/Wavs/',sep=''),     detect_pattern=NA,     top_model_path = ModelPath,     path_to_files = paste(tempdir(),'/MultiDir/Wav/',sep=''),     downsample_rate = 'NA',     save_wav = F,     class_names = c('female.gibbon','hornbill.helmeted','hornbill.rhino','long.argus','noise'),     noise_category = 'noise',     single_class = FALSE,     threshold = .25,     max_freq_khz = 2   )  } } #> Error in cpp_tensor_load(obj$values, device, base64): Lantern is not loaded. Please use `install_torch()` to install additional dependencies."},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","text":"Given trained models set images, function evaluates performance models.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","text":"","code":"evaluate_trainedmodel_performance(   trained_models_dir,   image_data_dir,   output_dir = \"data/\",   positive.class = \"Gibbons\",   negative.class = \"Noise\" )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","text":"trained_models_dir Path directory containing trained models (.pt files). image_data_dir Path directory containing image data evaluation. output_dir Path directory performance scores saved. positive.class Label positive class. negative.class Label negative class.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","text":"Invisible NULL. performance scores written specified output directory.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance","text":"","code":"{ } #> NULL"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","text":"Given trained models set images, function evaluates performance models.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","text":"","code":"evaluate_trainedmodel_performance_multi(   trained_models_dir,   image_data_dir,   output_dir = \"data/\",   class_names,   noise.category = \"noise\",   unfreeze = TRUE )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","text":"trained_models_dir Path directory containing trained models (.pt files). image_data_dir Path directory containing image data evaluation. output_dir Path directory performance scores saved. class_names Character vector specifying class names. User specified training data folders. noise.category Category label noise class. Default 'noise'. unfreeze Logical indicating whether unfreeze model parameters. User specified based trained model.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","text":"Invisible NULL. performance scores written specified output directory.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/evaluate_trainedmodel_performance_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate Model Performance on Image Data — evaluate_trainedmodel_performance_multi","text":"","code":"{ } #> NULL"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/extract_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Embeddings and Create Scatter Plots — extract_embeddings","title":"Extract Embeddings and Create Scatter Plots — extract_embeddings","text":"function loads fine-tuned Torch model, extracts embeddings set test images, performs dimensionality reduction using UMAP, creates scatter plots visualize embeddings.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/extract_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Embeddings and Create Scatter Plots — extract_embeddings","text":"","code":"extract_embeddings(test_input, model_path, target_class, unsupervised = \"TRUE\")"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/extract_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Embeddings and Create Scatter Plots — extract_embeddings","text":"test_input character string specifying path directory containing test images. model_path character string specifying path pre-trained PyTorch model file. target_class character string specifying class interest cluster analysis. unsupervised Logical, indicates whether assign 'target_class' cluster calculate NMI corresponding confusion matrix","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/extract_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Embeddings and Create Scatter Plots — extract_embeddings","text":"list containing following components: EmbeddingsCombined combined scatter plot embeddings, showing class cluster colors. NMI Normalized Mutual Information (NMI) score clustering results ground truth labels. ConfusionMatrix confusion matrix showing classification performance metrics.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/extract_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Embeddings and Create Scatter Plots — extract_embeddings","text":"","code":"{ #' Set model directory trained_models_dir <- system.file(\"extdata\", \"trainedresnetmulti/\", package = \"gibbonNetR\")  #' Specify model path ModelPath <- list.files(trained_models_dir,full.names = TRUE)  # Specify model path ImageFile <- system.file(\"extdata\", \"multiclass/test/\", package = \"gibbonNetR\")  # Function to extract and plot embeddings result <- extract_embeddings(test_input=ImageFile,                              model_path =ModelPath,                              target_class = \"female.gibbon\",                              unsupervised='TRUE' )  print(result$EmbeddingsCombined) } #> Error in cpp_tensor_load(obj$values, device, base64): Lantern is not loaded. Please use `install_torch()` to install additional dependencies."},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/get_best_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Best Performance Results from Performance Tables — get_best_performance","title":"Extract Best Performance Results from Performance Tables — get_best_performance","text":"Given path directory performance tables, function reads tables, combines , extracts best performance results based various criteria.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/get_best_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Best Performance Results from Performance Tables — get_best_performance","text":"","code":"get_best_performance(   performancetables.dir,   model.type = \"multi\",   class = \"hornbill.helmeted\",   Thresh.val = 0.5 )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/get_best_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Best Performance Results from Performance Tables — get_best_performance","text":"performancetables.dir Path directory containing performance tables. model.type Type model architecture. 'multi' treat multiclass, otherwise treat binary. class Specific class evaluation. Thresh.val Threshold value evaluation.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/get_best_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Best Performance Results from Performance Tables — get_best_performance","text":"list containing best F1 scores, best precision results, best recall results, plots visualizing metrics.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/get_best_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Best Performance Results from Performance Tables — get_best_performance","text":"","code":"{ # Simulate data for performance tables set.seed(123)  #' Set directory performance_tables_dir <- paste(tempdir(),\"/example_performance_tables/\", sep='')  #' Create directory for performance tables (NOTE THIS IS FOR TESTING ONLY) dir.create(performance_tables_dir, showWarnings = FALSE, recursive = TRUE)  #' Define list of model architectures architectures <- c(\"alexnet\", \"vgg16\", \"vgg19\")  #' Define list of training datasets training_datasets <- c(\"Dataset1\", \"Dataset2\", \"Dataset3\")  #' Create performance tables for (arch in architectures) {   for (td in training_datasets) {     #' Generate random performance metrics     metrics <- data.frame(       Class = rep(c(\"hornbill.helmeted\", \"other.class\"), each = 5),       \"Training Data\" = rep(td, 10),       \"CNN Architecture\" = rep(arch, 10),       Threshold = runif(10, 0, 1),       F1 = runif(10, 0, 1),       Precision = runif(10, 0, 1),       Recall = runif(10, 0, 1),       AUC = runif(10, 0, 1),       `N epochs` = rep(c(10, 20, 30), each = 10)     )     # Reassign column names     colnames(metrics) <- c(\"Class\",     \"Training Data\", \"CNN Architecture\",     \"Threshold\", \"F1\", \"Precision\",     \"Recall\", \"AUC\", \"N epochs\")     #' Write data to CSV file     filename <- paste0(performance_tables_dir, arch, \"_\", td, \".csv\")     write.csv(metrics, filename, row.names = FALSE)   } }   #' Call the function with default parameters results <- get_best_performance(performancetables.dir = performance_tables_dir, )   # NOTE: Results will not make sense as it is random #' Print the best F1 scores print(\"Best F1 scores:\") print(results$best_f1)  #' Print the best precision results print(\"Best precision results:\") print(results$best_precision)  #' Print the best recall results print(\"Best recall results:\") print(results$best_recall)  #' Print the best AUC results print(\"Best AUC results:\") print(results$best_auc)  #' Plot F1 scores print(results$f1_plot)  #' Plot precision-recall curve print(results$pr_plot) } #> [1] \"Evaluating performance for hornbill.helmeted Here are the present classes: hornbill.helmeted\" #> [2] \"Evaluating performance for hornbill.helmeted Here are the present classes: other.class\"       #> [1] \"Best F1 results\" #> [1] \"hornbill.helmeted\" \"hornbill.helmeted\" \"hornbill.helmeted\" #> [4] \"hornbill.helmeted\" \"hornbill.helmeted\" \"hornbill.helmeted\" #> [7] \"hornbill.helmeted\" \"hornbill.helmeted\" \"hornbill.helmeted\" #>               Class Training Data CNN Architecture Threshold        F1 #> 1 hornbill.helmeted      Dataset1            vgg19 0.7790659 0.7132790 #> 2 hornbill.helmeted      Dataset1            vgg19 0.7790659 0.7132790 #> 3 hornbill.helmeted      Dataset1            vgg19 0.7790659 0.7132790 #> 4 hornbill.helmeted      Dataset2            vgg19 0.5150718 0.8967387 #> 5 hornbill.helmeted      Dataset2            vgg19 0.5150718 0.8967387 #> 6 hornbill.helmeted      Dataset2            vgg19 0.5150718 0.8967387 #> 7 hornbill.helmeted      Dataset3          alexnet 0.9544738 0.9477269 #> 8 hornbill.helmeted      Dataset3          alexnet 0.9544738 0.9477269 #> 9 hornbill.helmeted      Dataset3          alexnet 0.9544738 0.9477269 #>   Precision    Recall       AUC N epochs #> 1 0.1470483 0.7377974 0.5260297       10 #> 2 0.1470483 0.7377974 0.5260297       20 #> 3 0.1470483 0.7377974 0.5260297       30 #> 4 0.8664833 0.3727094 0.7259830       10 #> 5 0.8664833 0.3727094 0.7259830       20 #> 6 0.8664833 0.3727094 0.7259830       30 #> 7 0.2197676 0.7370777 0.1838495       10 #> 8 0.2197676 0.7370777 0.1838495       20 #> 9 0.2197676 0.7370777 0.1838495       30 #> [1] \"Best Precision results\" #>               Class Training Data CNN Architecture Threshold        F1 #> 1 hornbill.helmeted      Dataset1          alexnet 0.8830174 0.5726334 #> 2 hornbill.helmeted      Dataset2            vgg16 0.9623589 0.2529649 #> 3 hornbill.helmeted      Dataset3            vgg16 0.5310704 0.5164449 #>   Precision     Recall       AUC N epochs #> 1 0.9942698 0.79546742 0.3688455       10 #> 2 0.9611048 0.42842151 0.6623176       10 #> 3 0.7703341 0.05795856 0.7542474       10 #> [1] \"Best Recall results\" #>               Class Training Data CNN Architecture Threshold        F1 #> 1 hornbill.helmeted      Dataset1          alexnet 0.7883051 0.4533342 #> 2 hornbill.helmeted      Dataset2            vgg19 0.9674695 0.1928159 #> 3 hornbill.helmeted      Dataset3            vgg19 0.5763018 0.4979489 #>   Precision    Recall       AUC N epochs #> 1 0.6928034 0.9022990 0.4145463       10 #> 2 0.3428088 0.7608236 0.2963022       10 #> 3 0.3219374 0.9966172 0.1655209       10 #> [1] \"Best AUC results\" #>               Class Training Data CNN Architecture Threshold        F1 #> 1 hornbill.helmeted      Dataset1            vgg19 0.7790659 0.7132790 #> 2 hornbill.helmeted      Dataset2            vgg19 0.5150718 0.8967387 #> 3 hornbill.helmeted      Dataset3            vgg16 0.5310704 0.5164449 #>   Precision     Recall       AUC N epochs #> 1 0.1470483 0.73779740 0.5260297       10 #> 2 0.8664833 0.37270939 0.7259830       10 #> 3 0.7703341 0.05795856 0.7542474       10 #> [1] \"Best F1 scores:\" #> # A tibble: 9 × 9 #>   Class      `Training Data` `CNN Architecture` Threshold    F1 Precision Recall #>   <chr>      <chr>           <chr>                  <dbl> <dbl>     <dbl>  <dbl> #> 1 hornbill.… Dataset1        vgg19                  0.779 0.713     0.147  0.738 #> 2 hornbill.… Dataset1        vgg19                  0.779 0.713     0.147  0.738 #> 3 hornbill.… Dataset1        vgg19                  0.779 0.713     0.147  0.738 #> 4 hornbill.… Dataset2        vgg19                  0.515 0.897     0.866  0.373 #> 5 hornbill.… Dataset2        vgg19                  0.515 0.897     0.866  0.373 #> 6 hornbill.… Dataset2        vgg19                  0.515 0.897     0.866  0.373 #> 7 hornbill.… Dataset3        alexnet                0.954 0.948     0.220  0.737 #> 8 hornbill.… Dataset3        alexnet                0.954 0.948     0.220  0.737 #> 9 hornbill.… Dataset3        alexnet                0.954 0.948     0.220  0.737 #> # ℹ 2 more variables: AUC <dbl>, `N epochs` <dbl> #> [1] \"Best precision results:\" #> # A tibble: 3 × 9 #>   Class      `Training Data` `CNN Architecture` Threshold    F1 Precision Recall #>   <chr>      <chr>           <chr>                  <dbl> <dbl>     <dbl>  <dbl> #> 1 hornbill.… Dataset1        alexnet                0.883 0.573     0.994 0.795  #> 2 hornbill.… Dataset2        vgg16                  0.962 0.253     0.961 0.428  #> 3 hornbill.… Dataset3        vgg16                  0.531 0.516     0.770 0.0580 #> # ℹ 2 more variables: AUC <dbl>, `N epochs` <dbl> #> [1] \"Best recall results:\" #> # A tibble: 3 × 9 #>   Class      `Training Data` `CNN Architecture` Threshold    F1 Precision Recall #>   <chr>      <chr>           <chr>                  <dbl> <dbl>     <dbl>  <dbl> #> 1 hornbill.… Dataset1        alexnet                0.788 0.453     0.693  0.902 #> 2 hornbill.… Dataset2        vgg19                  0.967 0.193     0.343  0.761 #> 3 hornbill.… Dataset3        vgg19                  0.576 0.498     0.322  0.997 #> # ℹ 2 more variables: AUC <dbl>, `N epochs` <dbl> #> [1] \"Best AUC results:\" #> # A tibble: 3 × 9 #>   Class      `Training Data` `CNN Architecture` Threshold    F1 Precision Recall #>   <chr>      <chr>           <chr>                  <dbl> <dbl>     <dbl>  <dbl> #> 1 hornbill.… Dataset1        vgg19                  0.779 0.713     0.147 0.738  #> 2 hornbill.… Dataset2        vgg19                  0.515 0.897     0.866 0.373  #> 3 hornbill.… Dataset3        vgg16                  0.531 0.516     0.770 0.0580 #> # ℹ 2 more variables: AUC <dbl>, `N epochs` <dbl>"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/spectrogram_images.html","id":null,"dir":"Reference","previous_headings":"","what":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","title":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","text":"Process Save Spectrogram Images Sound Files","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/spectrogram_images.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","text":"","code":"spectrogram_images(   trainingBasePath,   outputBasePath,   splits,   random = \"TRUE\",   minfreq.khz = 0.4,   maxfreq.khz = 1.6,   new.sampleratehz = 16000 )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/spectrogram_images.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","text":"trainingBasePath Base directory containing training folders. outputBasePath Directory processed images saved. splits Numeric vector specifying split ratios train, valid, test sets. Defaults c(0.8, 0.1, 0.1). random Logical. TRUE randomly samples folder, FALSE divides sets based alphabetic file name sequence. minfreq.khz Minimum frequency kHz spectrogram. Defaults 0.4. maxfreq.khz Maximum frequency kHz spectrogram. Defaults 2. new.sampleratehz New sample rate Hz resampling audio. Defaults 16000. Set 'NA' resampling required.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/spectrogram_images.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","text":"Invisible NULL","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/spectrogram_images.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process and Save Spectrogram Images from Sound Files — spectrogram_images","text":"","code":"{ if (.Platform$OS.type == \"unix\") { # Load the gibbonNetR package library(gibbonNetR) library(torchvision) library(torch)  # Load data data(\"TempBinWav\")  # Define the output directory output.dir <- paste(tempdir(), '/MultiDir/Noise/')  # Create the output directory dir.create(output.dir, recursive = TRUE, showWarnings = FALSE)  # Define the intervals for cutting the wave cutwave.list <- seq(1, 30, 5)  # Extract subsamples from the waveform subsamps <- lapply(1:(length(cutwave.list) - 1),                    function(i)                      extractWave(                        TempBinWav,                        from = cutwave.list[i],                        to = cutwave.list[i + 1],                        xunit = c(\"time\"),                        plot = FALSE,                        output = \"Wave\"                      ))  # Write the extracted subsamples to .wav files lapply(1:length(subsamps),        function(i)          writeWave(            subsamps[[i]],            filename = paste(              output.dir,              'temp_', i, '_', '.wav',              sep = ''            ),            extensible = FALSE          ) )  # List the files in the output directory list.files(output.dir)  # Generate spectrogram images spectrogram_images(   trainingBasePath = paste(tempdir(), '/MultiDir/'),   outputBasePath = paste(tempdir(), '/MultiDir/', 'Spectro/', sep = ''),   splits = c(1, 0, 0),   new.sampleratehz = 'NA' )  # List the images generated ListImages <- list.files(paste(tempdir(), '/MultiDir/', 'Spectro/', sep = ''), recursive = TRUE)  print(ListImages)  # Get the path of a single image Singlepath <- list.files(paste(tempdir(), '/MultiDir/', 'Spectro/', sep = ''), recursive = TRUE, full.names = TRUE)[1]  # Set input data path input.data.path <- paste(tempdir(), '/MultiDir/', 'Spectro/train/', sep = '')  # Load images in path train_ds <- image_folder_dataset(   file.path(input.data.path),   #' Path to the image directory   transform = . %>%     torchvision::transform_to_tensor() %>%     torchvision::transform_resize(size = c(224, 224)) %>%     torchvision::transform_normalize(       mean = c(0.485, 0.456, 0.406),      #' Mean for normalization       std = c(0.229, 0.224, 0.225)        #' Standard deviation for normalization     ),   target_transform = function(x) as.double(x) - 1  #' Transformation for target/labels )  # Create a dataloader from the dataset: train_dl <- dataloader(train_ds, batch_size = train_ds$.length(), shuffle = FALSE, drop_last = TRUE)  # Extract the next batch from the dataloader batch <- train_dl$.iter()$.next()  # Extract the labels for the batch and determine class names classes <- batch[[2]] class_names <- list.files(input.data.path,recursive = TRUE) class_names <- str_split_fixed(class_names,pattern = '/',n=2)[,1]  # Convert the batch tensor of images to an array and process them: images <- as_array(batch[[1]]) %>% aperm(perm = c(1, 3, 4, 2))  # Set the plotting parameters par(mfcol = c(3,4), mar = rep(1, 4))  #Define a function to normalize pixel values normalize_pixel_values <- function(image) {   normalized_image <- (image - min(image)) / (max(image) - min(image))   return(normalized_image) }  images %>%         purrr::array_tree(1) %>%         purrr::set_names(class_names) %>%         purrr::map(~ as.raster(normalize_pixel_values(.x))) %>%         purrr::iwalk(~{plot(.x); title(.y)})         }         } #> Error in shuffled_indices[-c(train_idx, valid_idx)]: only 0's may be mixed with negative subscripts"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Train Binary CNN Models — train_CNN_binary","title":"Train Binary CNN Models — train_CNN_binary","text":"function trains Convolutional Neural Network (CNN) models, AlexNet, VGG16, VGG19, ResNet18, ResNet50, ResNet152, given dataset. trained model saved along metadata usage.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train Binary CNN Models — train_CNN_binary","text":"","code":"train_CNN_binary(   input.data.path,   test.data,   architecture,   noise.weight = 0.5,   unfreeze.param = TRUE,   batch_size = 32,   learning_rate,   save.model = FALSE,   epoch.iterations = 1,   early.stop = \"yes\",   output.base.path = \"data/\",   trainingfolder,   list.thresholds = seq(0.1, 1, 0.1),   positive.class = \"Gibbons\",   negative.class = \"Noise\" )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train Binary CNN Models — train_CNN_binary","text":"input.data.path Character. path folder containing training data. test.data Character. path folder containing test data. architecture Character. CNN architecture use ('alexnet', 'vgg16', 'vgg19', 'resnet18', 'resnet50', 'resnet152'). noise.weight Numeric. Assigned weight noise class. Default 0.5. unfreeze.param Logical. Determines whether unfreeze.param layers pretrained CNN retraining. Default TRUE. batch_size Numeric. Batch size training model. Default 32. learning_rate Numeric. learning rate training model. save.model Logical. Whether save trained model future use. Default FALSE. epoch.iterations Numeric. number epochs training model. Default 1. early.stop Character. Determines whether early stopping applied . Options: \"yes\" \"\". Default 'yes'. output.base.path Character. base path output files saved. Default 'data/'. trainingfolder Character. descriptor training data used naming output files. list.thresholds Numerical list indicating thresholds. Default seq(0.1,1,.1). positive.class Character. name positive class label. Default 'Gibbons'. negative.class Character. name negative class label. Default 'Noise'.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train Binary CNN Models — train_CNN_binary","text":"list containing two elements: Output_Path: path model metadata saved. Metadata: dataframe containing metadata training session.","code":""},{"path":[]},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Train Binary CNN Models — train_CNN_binary","text":"","code":"{ input.data.path <- system.file(\"extdata\", \"binary/\", package = \"gibbonNetR\")   test.data <- system.file(\"extdata\", \"binary/test/\", package = \"gibbonNetR\")   result <- train_CNN_binary(     input.data.path = input.data.path,     test.data = test.data,     architecture = \"alexnet\",  # Choose architecture     unfreeze.param = TRUE,     batch_size = 6,     learning_rate = 0.001,     epoch.iterations = 1,  # Or any other list of integer epochs     early.stop = \"yes\",     output.base.path = paste(tempdir(),'/',sep=''),     trainingfolder = \"test_binary\"   )   print(result) } #> Error in cpp_cuda_is_available(): Lantern is not loaded. Please use `install_torch()` to install additional dependencies."},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Train Multi-class pretrained CNN Models — train_CNN_multi","title":"Train Multi-class pretrained CNN Models — train_CNN_multi","text":"function facilitates training convolutional neural network (CNN) models using various transfer learning architectures AlexNet, VGG16, VGG19, ResNet18, ResNet50, ResNet152, given dataset. trained model saved along metadata usage.","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train Multi-class pretrained CNN Models — train_CNN_multi","text":"","code":"train_CNN_multi(   input.data.path,   test.data,   architecture,   unfreeze.param = TRUE,   batch_size = 32,   learning_rate,   save.model = FALSE,   class_weights = c(0.49, 0.49, 0.02),   epoch.iterations = 1,   early.stop = \"yes\",   output.base.path = tempdir(),   trainingfolder,   noise.category = \"Noise\" )"},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train Multi-class pretrained CNN Models — train_CNN_multi","text":"input.data.path Character. Path input data folder. test.data Character. Path test data folder. architecture Character. Specifies CNN architecture use ('alexnet', 'vgg16', 'vgg19', 'resnet18', 'resnet50', 'resnet152'). unfreeze.param Logical. Indicates whether layers pretrained CNN unfrozen retraining. Default TRUE. batch_size Numeric. Batch size training model. Default 32. learning_rate Numeric. Learning rate training model. save.model Logical. Specifies whether save trained model future use. Default FALSE. class_weights Numeric vector. Weights assigned different classes handling class imbalance. Default c(0.49, 0.49, 0.02). epoch.iterations List integers. Number epochs training model. Default 1. early.stop Character. Indicates whether early stopping applied . Use \"yes\" apply \"\" skip. Default 'yes'. output.base.path Character. Base path output files saved. Default 'data/'. trainingfolder Character. descriptive name training data, used naming output files. noise.category Character. Label noise category. Default \"Noise\".","code":""},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train Multi-class pretrained CNN Models — train_CNN_multi","text":"list containing two elements: Output_Path: Path trained model metadata saved. Metadata: dataframe containing metadata training session.","code":""},{"path":[]},{"path":"https://denajgibbon.github.io/gibbonNetR/reference/train_CNN_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Train Multi-class pretrained CNN Models — train_CNN_multi","text":"","code":"{ { input.data.path <- system.file(\"extdata\", \"multiclass/\", package = \"gibbonNetR\")   test.data <- system.file(\"extdata\", \"multiclass/test/\", package = \"gibbonNetR\")   result <- train_CNN_multi(   input.data.path = input.data.path,   test.data = test.data,   architecture = \"alexnet\",  # Choose architecture   unfreeze.param = TRUE,   class_weights = rep( (1/5), 5),   batch_size = 6,   learning_rate = 0.001,   epoch.iterations = 1,  # Or any other list of integer epochs   early.stop = \"yes\",   output.base.path = paste(tempdir(),'/',sep=''),   trainingfolder = \"test\",   noise.category = 'noise' ) print(result) } } #> Error in cpp_cuda_is_available(): Lantern is not loaded. Please use `install_torch()` to install additional dependencies."}]
